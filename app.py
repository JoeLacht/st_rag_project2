import streamlit as st
import numpy as np
import joblib
import faiss
from langchain_huggingface import HuggingFaceEmbeddings
from symspellpy import SymSpell, Verbosity
from sentence_transformers import CrossEncoder
import os, getpass
from langchain_groq import ChatGroq
from langchain_core.messages import SystemMessage, HumanMessage

st.cache_data.clear()
st.cache_resource.clear()

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã ---
st.set_page_config(
    page_title="üé• –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ —Ñ–∏–ª—å–º–æ–≤",
    page_icon="üé¨",
    layout="wide"
)
st.title("üé¨ –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ —Ñ–∏–ª—å–º–æ–≤")
st.markdown("–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å, –∏ —è –ø–æ–¥–±–µ—Ä—É –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —Ñ–∏–ª—å–º—ã —Å —é–º–æ—Ä–æ–º ü§ì‚ú®")

# --- –ó–∞–≥—Ä—É–∑–∫–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏ Faiss ---
embeddings = np.load("movie_embeds.npy")
meta = joblib.load("movie_meta.pkl")
index = faiss.read_index("faiss_index.bin")

dim = embeddings.shape[1]

# --- Embeddings –º–æ–¥–µ–ª—å ---
embeddings_model = HuggingFaceEmbeddings(
    model_name="intfloat/multilingual-e5-base",
    model_kwargs={"device": "cpu"},
    encode_kwargs={"normalize_embeddings": True, "batch_size": 64}
)

# --- SymSpell –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ–ø–µ—á–∞—Ç–æ–∫ ---
from symspellpy import SymSpell, Verbosity

max_edit_distance_dictionary = 2
prefix_length = 7
sym_spell = SymSpell(max_edit_distance_dictionary, prefix_length)

# —Ñ—É–Ω–∫—Ü–∏—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ split
def safe_split(s, sep=' '):
    return str(s).split(sep) if isinstance(s, str) else []

# —Å–æ–∑–¥–∞—ë–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è SymSpell
vocab = set()
for m in meta:
    for w in safe_split(m.get("movie_title")):
        vocab.add(w.lower())
    for w in safe_split(m.get("categories"), sep=','):
        vocab.add(w.lower())

# –∑–∞–≥—Ä—É–∂–∞–µ–º –≤ symspell
for w in vocab:
    sym_spell.create_dictionary_entry(w, 1)

# —Ñ—É–Ω–∫—Ü–∏—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞
def symspell_correct_query(query: str):
    words = query.split()
    corrected = []
    for w in words:
        suggestions = sym_spell.lookup(w.lower(), Verbosity.TOP, max_edit_distance=2)
        if suggestions:
            corrected.append(suggestions[0].term)
        else:
            corrected.append(w)
    return " ".join(corrected)

# --- CrossEncoder –¥–ª—è rerank ---
cross_encoder = CrossEncoder("cross-encoder/ms-marco-MiniLM-L-6-v2", device="cpu")

# --- –§—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ ---
def search(query, top_k_faiss=50, top_k_return=10, apply_symspell=True):
    q0 = query
    if apply_symspell:
        q = symspell_correct_query(query)
    else:
        q = query

    q_emb = embeddings_model.embed_query(q)
    q_emb = np.array(q_emb, dtype=np.float32).reshape(1, -1)

    D, I = index.search(q_emb, top_k_faiss)
    candidate_idxs = I[0].tolist()

    candidates = []
    for idx in candidate_idxs:
        if idx < 0: continue
        candidates.append((meta[idx]['movie_title'], idx))

    cross_inputs = [[q0, meta[idx]['description']] for _, idx in candidates]
    rerank_scores = cross_encoder.predict(cross_inputs)

    ranked = sorted(zip([idx for _, idx in candidates], rerank_scores), key=lambda x: x[1], reverse=True)
    top_ranked = ranked[:top_k_return]

    results = []
    for idx, score in top_ranked:
        m = meta[idx]
        results.append({
            'score': float(score),
            'idx': idx,
            'movie_title': m.get('movie_title'),
            'release_date': m.get('release_date'),
            'page_url': m.get('page_url'),
            'image_url': m.get('image_url'),
            'directors': m.get('directors'),
            'actors': m.get('actors'),
            'genres': m.get('categories'),
            'description': m.get('description')
        })
    return results

# --- UI ---
query = st.text_input("üîç –í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å:", "–∫–æ—Å–º–æ—Å, –∫–æ–º–µ–¥–∏—è")
k_value = st.slider("üìä –°–∫–æ–ª—å–∫–æ —Ñ–∏–ª—å–º–æ–≤ –ø–æ–∫–∞–∑–∞—Ç—å:", 1, 10, 3)
temperature_value = st.slider(
    "üî• –ö—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞ (temperature):", 
    min_value=0.0, 
    max_value=1.5, 
    value=0.7, 
    step=0.05
)
apply_spell = st.checkbox("–ò—Å–ø—Ä–∞–≤–ª—è—Ç—å –æ–ø–µ—á–∞—Ç–∫–∏", True)

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ LLM ---
os.environ["GROQ_API_KEY"] = st.secrets["GROQ_API_KEY"]
llm = ChatGroq(model="openai/gpt-oss-120b", temperature=temperature_value, max_tokens=4096)

SYSTEM_PROMPT = """–¢—ã –∫–∏–Ω–æ–∫—Ä–∏—Ç–∏–∫ —Å –º–Ω–æ–≥–æ–ª–µ—Ç–Ω–∏–º –æ–ø—ã—Ç–æ–º –∏ –æ—Ç–ª–∏—á–Ω—ã–º —á—É–≤—Å—Ç–≤–æ–º —é–º–æ—Ä–∞! üéØ
    –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ —Ñ–∏–ª—å–º—ã –∏ –¥–∞—Ç—å –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—É—é –æ—Ü–µ–Ω–∫—É —Å –¥–æ–ª–µ–π –∏—Ä–æ–Ω–∏–∏.

    –°—Ç–∏–ª—å –∞–Ω–∞–ª–∏–∑–∞:
    - –ü—Ä–æ–≤–æ–¥–∏ –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑, —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è, —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏, —Å–≤—è–∑–∏ –º–µ–∂–¥—É –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è–º–∏, –Ω–æ —Å –ª–µ–≥–∫–æ–π –∏—Ä–æ–Ω–∏–µ–π
    - –ò—Å–ø–æ–ª—å–∑—É–π –∫–∏–Ω–æ-–º–µ–º—ã –∏ —à—É—Ç–∫–∏ —Ç–∞–º, –≥–¥–µ —ç—Ç–æ —É–º–µ—Å—Ç–Ω–æ
    - –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –æ—Ç–≤–µ—Ç —Å —ç–º–æ–¥–∑–∏ –∏ –∑–∞–±–∞–≤–Ω—ã–º–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏
    - –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ –∂–∏–≤—ã–º, –Ω–æ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–º —Ç–æ–Ω–æ–º

    –ü–æ–º–Ω–∏: —é–º–æ—Ä –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –¥–æ–±—Ä—ã–º –∏ –Ω–µ –æ—Å–∫–æ—Ä–±–∏—Ç–µ–ª—å–Ω—ã–º. –¶–µ–ª—å - —Å–¥–µ–ª–∞—Ç—å –∞–Ω–∞–ª–∏–∑ –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–º!

    –ï—Å–ª–∏ —Å—Ä–µ–¥–∏ —Ñ–∏–ª—å–º–æ–≤ –µ—Å—Ç—å —á—Ç–æ-—Ç–æ –æ—Å–æ–±–µ–Ω–Ω–æ –∑–∞–±–∞–≤–Ω–æ–µ - –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —ç—Ç–æ –æ—Ç–º–µ—Ç—å! üòÑ"""

def build_rag_context(results, user_query, max_chars=1800):
    parts = []
    for r in results:
        s = f"Title: {r['movie_title']} ({r.get('release_date','')})\nGenres: {r.get('genres','')}\nDescription: {r.get('description')[:200]}\nURL: {r.get('page_url')}\n"
        parts.append(s)
    context = "\n\n".join(parts)
    if len(context) > max_chars:
        context = context[:max_chars]
    prompt = f"{SYSTEM_PROMPT}\n\nUser query: {user_query}\n\nContext:\n{context}\n\n–û—Ç–≤–µ—Ç:"
    return prompt

def rag_answer(user_query, results):
    prompt = build_rag_context(results, user_query)
    messages = [
        SystemMessage(content=SYSTEM_PROMPT),
        HumanMessage(content=f"Query: {user_query}\n\nContext:\n{build_rag_context(results, user_query)}")
    ]
    resp = llm(messages)
    return resp.content

import re

def clean_think_tags(text: str) -> str:
    # —É–¥–∞–ª—è–µ–º –≤—Å—ë –º–µ–∂–¥—É <think> –∏ </think> (–≤–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ)
    cleaned = re.sub(r"<think>.*?</think>", "", text, flags=re.DOTALL)
    return cleaned.strip()

if st.button("–ù–∞–π—Ç–∏ üéØ") and query.strip():
    with st.spinner("üöÄ –ü–æ–¥–±–∏—Ä–∞–µ–º —Ñ–∏–ª—å–º—ã..."):
        results = search(query, top_k_faiss=50, top_k_return=k_value, apply_symspell=apply_spell)
        # rag_resp = rag_answer(query, results)
        # # st.subheader("üé≠ –ê–Ω–∞–ª–∏–∑ –∫–∏–Ω–æ–∫—Ä–∏—Ç–∏–∫–∞:")
        # # st.markdown(rag_resp)
        rag_resp = rag_answer(query, results)
        rag_resp_clean = clean_think_tags(rag_resp)
        st.subheader("üé≠ –ê–Ω–∞–ª–∏–∑ –∫–∏–Ω–æ–∫—Ä–∏—Ç–∏–∫–∞:")
        st.markdown(rag_resp_clean)

        st.subheader("üé¨ –ù–∞–π–¥–µ–Ω–Ω—ã–µ —Ñ–∏–ª—å–º—ã:")
        for r in results:
            col1, col2 = st.columns([1,3])
            with col1:
                if r.get('image_url'):
                    st.image(r["image_url"], use_container_width=True)
            with col2:
                st.markdown(f"### [{r.get('movie_title','–ù–µ —É–∫–∞–∑–∞–Ω–æ')}]({r.get('page_url','#')})")
                st.markdown(f"**–ñ–∞–Ω—Ä—ã:** {r.get('genres','–ù–µ —É–∫–∞–∑–∞–Ω–æ')}")
                st.markdown(f"**–†–µ–∂–∏—Å—Å–µ—Ä:** {r.get('directors','–ù–µ —É–∫–∞–∑–∞–Ω–æ')}")
                st.markdown(f"**–ê–∫—Ç—ë—Ä—ã:** {r.get('actors','–ù–µ —É–∫–∞–∑–∞–Ω–æ')}")
                st.markdown(f"**–ì–æ–¥:** {r.get('release_date','–ù–µ —É–∫–∞–∑–∞–Ω–æ')}")
                st.markdown(f"**–°—Å—ã–ª–∫–∞ –Ω–∞ —Ñ–∏–ª—å–º:** {r.get('page_url','–ù–µ —É–∫–∞–∑–∞–Ω–æ')}")
                st.markdown(f"**–û–ø–∏—Å–∞–Ω–∏–µ:** {r.get('description')}...")
            st.markdown("---")